Ext.data.JsonP.Microsoft_ProjectOxford_SpeechRecognition_MicrophoneRecognitionClient({"tagname":"class","name":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","autodetected":{},"files":[{"filename":"speech.1.0.0.js","href":"speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient"}],"members":[{"name":"endMicAndRecognition","tagname":"method","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"method-endMicAndRecognition","meta":{}},{"name":"startMicAndRecognition","tagname":"method","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"method-startMicAndRecognition","meta":{}},{"name":"onError","tagname":"event","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"event-onError","meta":{}},{"name":"onFinalResponseReceived","tagname":"event","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"event-onFinalResponseReceived","meta":{}},{"name":"onIntentReceived","tagname":"event","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"event-onIntentReceived","meta":{}},{"name":"onPartialResponseReceived","tagname":"event","owner":"Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","id":"event-onPartialResponseReceived","meta":{}}],"alternateClassNames":[],"aliases":{},"id":"class-Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient","component":false,"superclasses":[],"subclasses":[],"mixedInto":[],"mixins":[],"parentMixins":[],"requires":[],"uses":[],"html":"<div><pre class=\"hierarchy\"><h4>Files</h4><div class='dependency'><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient' target='_blank'>speech.1.0.0.js</a></div></pre><div class='doc-contents'>\n</div><div class='members'><div class='members-section'><div class='definedBy'>Defined By</div><h3 class='members-title icon-method'>Methods</h3><div class='subsection'><div id='method-endMicAndRecognition' class='member first-child not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-method-endMicAndRecognition' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-method-endMicAndRecognition' class='name expandable'>endMicAndRecognition</a>( <span class='pre'></span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>The microphone is turned off and the connection to the Speech Recognition Server is severed. ...</div><div class='long'><p>The microphone is turned off and the connection to the Speech Recognition Server is severed.</p>\n</div></div></div><div id='method-startMicAndRecognition' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-method-startMicAndRecognition' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-method-startMicAndRecognition' class='name expandable'>startMicAndRecognition</a>( <span class='pre'></span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>The microphone is turned on and data from the microphone is sent to the Speech Recognition Service. ...</div><div class='long'><p>The microphone is turned on and data from the microphone is sent to the Speech Recognition Service.\nA built in Silence Detector is applied to the microphone data before it is sent to the recognition service.</p>\n</div></div></div></div></div><div class='members-section'><div class='definedBy'>Defined By</div><h3 class='members-title icon-event'>Events</h3><div class='subsection'><div id='event-onError' class='member first-child not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-event-onError' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-event-onError' class='name expandable'>onError</a>( <span class='pre'>errorCode, response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when an error is detected. ...</div><div class='long'><p>Invoked when an error is detected.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>errorCode</span> : Object<div class='sub-desc'><p>{number} The error code.</p>\n</div></li><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>The body of the http response for the error.</p>\n</div></li></ul></div></div></div><div id='event-onFinalResponseReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-event-onFinalResponseReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-event-onFinalResponseReceived' class='name expandable'>onFinalResponseReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>In ShortPhrase mode, the client gets one final multiple n-best choice result\nwhen recognition is complete. ...</div><div class='long'><p>In ShortPhrase mode, the client gets one final multiple n-best choice result\nwhen recognition is complete.  This event will be fired for that one final\nmultiple n-best choice result.</p>\n\n<p>In LongDictation mode, the client will receive multiple final results,\nbased on where the server thinks sentence pauses are. This event will be fired\nfor each final result, as the server determines them.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>A streamlined RecognitionResult which contains the n-best recognized\n                text results and their confidences.  A StreamlinedRecognitionResults can\n                then further be used to obtain a SpeechRecognitionResults which has even\n                more n-best result data.</p>\n</div></li></ul></div></div></div><div id='event-onIntentReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-event-onIntentReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-event-onIntentReceived' class='name expandable'>onIntentReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when an intent event is received. ...</div><div class='long'><p>Invoked when an intent event is received.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>{string} The structured intent response.</p>\n</div></li></ul></div></div></div><div id='event-onPartialResponseReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient'>Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-ProjectOxford-SpeechRecognition-MicrophoneRecognitionClient-event-onPartialResponseReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.ProjectOxford.SpeechRecognition.MicrophoneRecognitionClient-event-onPartialResponseReceived' class='name expandable'>onPartialResponseReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when during the recognition process, the Speech Recognition\nserver can create a hypothesis on what the recogn...</div><div class='long'><p>Invoked when during the recognition process, the Speech Recognition\nserver can create a hypothesis on what the recognized text might be.  As more audio\nstreams in, the hypothesis might change, and get longer as well.  So with each\nhypothesis, the server will call back and this event will be fired and contain\nthe current hypothesis text.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : string<div class='sub-desc'><p>The display text</p>\n</div></li></ul></div></div></div></div></div></div></div>","meta":{}});