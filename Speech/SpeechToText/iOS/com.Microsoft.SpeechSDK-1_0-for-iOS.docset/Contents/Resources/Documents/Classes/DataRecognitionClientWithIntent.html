<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">

	<title>DataRecognitionClientWithIntent Class Reference</title>

	<link rel="stylesheet" href="../css/style.css">
	<meta name="viewport" content="initial-scale=1, maximum-scale=1.4">
	<meta name="generator" content="appledoc 2.2.1 (build 1333)">
</head>
<body class="appledoc">
	<header>
		<div class="container" class="hide-in-xcode">
			
			<h1 id="library-title">
				<a href="../index.html">SpeechSDK-1_0-for-iOS </a>
			</h1>

			<p id="developer-home">
				<a href="../index.html">Microsoft</a>
			</p>
			
		</div>
	</header>

	<aside>
		<div class="container">
			<nav>
				<ul id="header-buttons" role="toolbar">
					<li><a href="../index.html">Index</a></li>
<li><a href="../hierarchy.html">Hierarchy</a></li>

					<li id="on-this-page" role="navigation">
						<label>
							On This Page

							<div class="chevron">
								<div class="chevy chevron-left"></div>
								<div class="chevy chevron-right"></div>
							</div>

							<select id="jump-to">
	<option value="top">Jump To&#133;</option>
	
	<option value="overview">Overview</option>
	

	
	
	<option value="tasks">Tasks</option>
	
	

	
	

	

	
	<optgroup label="Instance Methods">
		
		<option value="//api/name/initWithSpeechRecoParams:withProtocol:">- initWithSpeechRecoParams:withProtocol:</option>
		
	</optgroup>
	
	
</select>
						</label>
					</li>
				</ul>
			</nav>
		</div>
	</aside>

	<article>
		<div id="overview_contents" class="container">
			<div id="content">
				<main role="main">
					<h1 class="title">DataRecognitionClientWithIntent Class Reference</h1>

					
					<div class="section section-specification"><table cellspacing="0"><tbody>
						<tr>
	<th>Inherits from</th>
	<td><a href="../Classes/DataRecognitionClient.html">DataRecognitionClient</a> : <a href="../Classes/Conversation.html">Conversation</a> : NSObject</td>
</tr><tr>
	<th>Declared in</th>
	<td>DataRecognitionClientWithIntent.mm<br />SpeechRecognitionService.h</td>
</tr>
						</tbody></table></div>
					

                    
					
					<div class="section section-overview">
						<a title="Overview" name="overview"></a>
						<h2 class="subtitle subtitle-overview">Overview</h2>
						<p>The Azure Intelligent Services API client to perform speech and intent recognition from a buffered data source (e.g. a file or Bluetooth audio source).</p>




<p>Data is broken up into buffers and each buffer is sent to the speech recognition service.

No modification is done to the buffers; if silence detection is required, it must be performed in an external pre-processing pass over the data.

The audio data must be PCM, mono, 16-bit sample, with sample rate of 16000 Hz.</p>




<p>Returns both speech recognition results *and* structured intent results (see [https://LUIS.ai](https://LUIS.ai)).</p>

					</div>
					
					

					
					
					<div class="section section-tasks">
						<a title="Tasks" name="tasks"></a>
						

						
						

						<div class="task-list">
							<div class="section-method">
	<a name="//api/name/initWithSpeechRecoParams:withProtocol:" title="initWithSpeechRecoParams:withProtocol:"></a>
	<h3 class="method-title"><code><a href="#//api/name/initWithSpeechRecoParams:withProtocol:">&ndash;&nbsp;initWithSpeechRecoParams:withProtocol:</a></code>
</h3>

	<div class="method-info">
		<div class="pointy-thing"></div>

		<div class="method-info-container">
			
			
			<div class="method-subsection brief-description">
				<p>Initializes a speech recognition client that uses the buffered data as the input source.</p>
			</div>
			
		    

			<div class="method-subsection method-declaration"><code>- (id)initWithSpeechRecoParams:(AdmRecoOnlyPreferences *)<em>prefs</em> withProtocol:(id&lt;SpeechRecognitionProtocol&gt;)<em>delegate</em></code></div>

		    
			
			<div class="method-subsection arguments-section parameters">
				<h4 class="method-subtitle parameter-title">Parameters</h4>
				<table class="argument-def parameter-def">
				
					<tr>
						<th scope="row" class="argument-name"><code>prefs</code></th>
						<td><p>A set of preferences used to configure the speech service.</p></td>
					</tr>
				
					<tr>
						<th scope="row" class="argument-name"><code>delegate</code></th>
						<td><p>The speech recognition protocol callback</p></td>
					</tr>
				
				</table>
			</div>
			

			
			<div class="method-subsection return">
				<h4 class="method-subtitle parameter-title">Return Value</h4>
				<p>The speech and intent recognition client</p>
			</div>
			

			

			
			<div class="method-subsection discussion-section">
				<h4 class="method-subtitle">Discussion</h4>
				<p>Initializes a speech recognition client that uses the buffered data as the input source.</p>

<p>Callers are responsible for acquiring the audio data and writing that data to input streams. The data is split into buffers; each buffer is sent to the speech recognition service.

No modification is done to the buffers; silence detection must be performed by an external algorithm before calling any methods to write data to the service. The service returns speech recognition results *and* structured intent results.

The audio must be PCM, mono, 16-bit sample, with sample rate of 16000 Hz.

</p>




<p>The service returns structured intent results in JSON form (see [https://LUIS.ai](https://LUIS.ai)).</p>

			</div>
			

			

			

			
			<div class="method-subsection declared-in-section">
				<h4 class="method-subtitle">Declared In</h4>
				<p><code class="declared-in-ref">DataRecognitionClientWithIntent.mm</code></p>
			</div>
			
			
		</div>
	</div>
</div>
						</div>
						
					</div>
					
					

                    
				</main>

				<footer>
					<div class="footer-copyright">
						
						<p class="copyright">Copyright &copy; 2016 Microsoft. All rights reserved. Updated: 2016-03-21</p>
						
						
						<p class="generator">Generated by <a href="http://appledoc.gentlebytes.com">appledoc 2.2.1 (build 1333)</a>.</p>
						
					</div>
				</footer>
			</div>
		</div>
	</article>

	<script src="../js/script.js"></script>
</body>
</html>