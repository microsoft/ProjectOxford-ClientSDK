<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_75) on Thu Oct 08 01:48:27 GMT 2015 -->
<title>SpeechRecognitionServiceFactory</title>
<meta name="date" content="2015-10-08">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SpeechRecognitionServiceFactory";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford"><span class="strong">Prev Class</span></a></li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html" target="_top">Frames</a></li>
<li><a href="SpeechRecognitionServiceFactory.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">com.microsoft.ProjectOxford</div>
<h2 title="Class SpeechRecognitionServiceFactory" class="title">Class SpeechRecognitionServiceFactory</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>com.microsoft.ProjectOxford.SpeechRecognitionServiceFactory</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="strong">SpeechRecognitionServiceFactory</span>
extends java.lang.Object</pre>
<div class="block">Use the AzureIntelligentServices to work with the Speech Recognition Service.
 This factory can be used to create an object with which to make a recognition
 request to the Speech Recognition Service.  There are four types of objects that
 this factory can create.

 <p>(1) A DataRecognitionClient -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return only text 
 recognition results.  The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.

 <p>(2) A DataRecognitionClientWithIntent -- for speech recognition with data (for example from a file 
 or audio source). The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai)
 service. The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.

 <p>(3) A MicrophoneRecognitionClient -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return only text 
 recognition results.

 <p>(4) A MicrophoneRecognitionClient -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai)
 service.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#DictationContext">DictationContext</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClient(android.app.Activity,%20com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String)">createDataClient</a></strong>(android.app.Activity&nbsp;activity,
                <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                java.lang.String&nbsp;language,
                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                java.lang.String&nbsp;primaryOrSecondaryKey)</code>
<div class="block">Create a DataRecognitionClient -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClient(android.app.Activity,%20com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String)">createDataClient</a></strong>(android.app.Activity&nbsp;activity,
                <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                java.lang.String&nbsp;language,
                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                java.lang.String&nbsp;primaryOrSecondaryKey,
                java.lang.String&nbsp;url)</code>
<div class="block">Create a DataRecognitionClient with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClient(com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String)">createDataClient</a></strong>(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                java.lang.String&nbsp;language,
                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                java.lang.String&nbsp;primaryOrSecondaryKey)</code>
<div class="block">Create a DataRecognitionClient -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClient(com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String)">createDataClient</a></strong>(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                java.lang.String&nbsp;language,
                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                java.lang.String&nbsp;primaryOrSecondaryKey,
                java.lang.String&nbsp;url)</code>
<div class="block">Create a DataRecognitionClient with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClientWithIntent(android.app.Activity,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createDataClientWithIntent</a></strong>(android.app.Activity&nbsp;activity,
                          java.lang.String&nbsp;language,
                          <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                          java.lang.String&nbsp;primaryOrSecondaryKey,
                          java.lang.String&nbsp;luisAppId,
                          java.lang.String&nbsp;luisSubscriptionId)</code>
<div class="block">Create a DataRecognitionClientWithIntent -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClientWithIntent(android.app.Activity,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createDataClientWithIntent</a></strong>(android.app.Activity&nbsp;activity,
                          java.lang.String&nbsp;language,
                          <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                          java.lang.String&nbsp;primaryOrSecondaryKey,
                          java.lang.String&nbsp;luisAppId,
                          java.lang.String&nbsp;luisSubscriptionId,
                          java.lang.String&nbsp;url)</code>
<div class="block">Create a DataRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClientWithIntent(java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createDataClientWithIntent</a></strong>(java.lang.String&nbsp;language,
                          <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                          java.lang.String&nbsp;primaryOrSecondaryKey,
                          java.lang.String&nbsp;luisAppId,
                          java.lang.String&nbsp;luisSubscriptionId)</code>
<div class="block">Create a DataRecognitionClientWithIntent -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createDataClientWithIntent(java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createDataClientWithIntent</a></strong>(java.lang.String&nbsp;language,
                          <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                          java.lang.String&nbsp;primaryOrSecondaryKey,
                          java.lang.String&nbsp;luisAppId,
                          java.lang.String&nbsp;luisSubscriptionId,
                          java.lang.String&nbsp;url)</code>
<div class="block">Create a DataRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClient(android.app.Activity,%20com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String)">createMicrophoneClient</a></strong>(android.app.Activity&nbsp;activity,
                      <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                      java.lang.String&nbsp;language,
                      <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                      java.lang.String&nbsp;primaryOrSecondaryKey)</code>
<div class="block">Create a MicrophoneRecognitionClient -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClient(android.app.Activity,%20com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String)">createMicrophoneClient</a></strong>(android.app.Activity&nbsp;activity,
                      <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                      java.lang.String&nbsp;language,
                      <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                      java.lang.String&nbsp;primaryOrSecondaryKey,
                      java.lang.String&nbsp;url)</code>
<div class="block">Create a MicrophoneRecognitionClient with Acoustic Model Adaptation -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClient(com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String)">createMicrophoneClient</a></strong>(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                      java.lang.String&nbsp;language,
                      <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                      java.lang.String&nbsp;primaryOrSecondaryKey)</code>
<div class="block">Create a MicrophoneRecognitionClient -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClient(com.microsoft.ProjectOxford.SpeechRecognitionMode,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String)">createMicrophoneClient</a></strong>(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                      java.lang.String&nbsp;language,
                      <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                      java.lang.String&nbsp;primaryOrSecondaryKey,
                      java.lang.String&nbsp;url)</code>
<div class="block">Create a MicrophoneRecognitionClient with Acoustic Model Adaptation -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClientWithIntent(android.app.Activity,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createMicrophoneClientWithIntent</a></strong>(android.app.Activity&nbsp;activity,
                                java.lang.String&nbsp;language,
                                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                java.lang.String&nbsp;primaryOrSecondaryKey,
                                java.lang.String&nbsp;luisAppId,
                                java.lang.String&nbsp;luisSubscriptionId)</code>
<div class="block">Create a MicrophoneRecognitionClientWithIntent -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClientWithIntent(android.app.Activity,%20java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createMicrophoneClientWithIntent</a></strong>(android.app.Activity&nbsp;activity,
                                java.lang.String&nbsp;language,
                                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                java.lang.String&nbsp;primaryOrSecondaryKey,
                                java.lang.String&nbsp;luisAppId,
                                java.lang.String&nbsp;luisSubscriptionId,
                                java.lang.String&nbsp;url)</code>
<div class="block">Create a MicrophoneRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClientWithIntent(java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createMicrophoneClientWithIntent</a></strong>(java.lang.String&nbsp;language,
                                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                java.lang.String&nbsp;primaryOrSecondaryKey,
                                java.lang.String&nbsp;luisAppId,
                                java.lang.String&nbsp;luisSubscriptionId)</code>
<div class="block">Create a MicrophoneRecognitionClientWithIntent -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static <a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a></code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#createMicrophoneClientWithIntent(java.lang.String,%20com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents,%20java.lang.String,%20java.lang.String,%20java.lang.String,%20java.lang.String)">createMicrophoneClientWithIntent</a></strong>(java.lang.String&nbsp;language,
                                <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                java.lang.String&nbsp;primaryOrSecondaryKey,
                                java.lang.String&nbsp;luisAppId,
                                java.lang.String&nbsp;luisSubscriptionId,
                                java.lang.String&nbsp;url)</code>
<div class="block">Create a MicrophoneRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition from the microphone.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html#getAPIVersion()">getAPIVersion</a></strong>()</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="DictationContext">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>DictationContext</h4>
<pre>public static final&nbsp;java.lang.String DictationContext</pre>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../constant-values.html#com.microsoft.ProjectOxford.SpeechRecognitionServiceFactory.DictationContext">Constant Field Values</a></dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="getAPIVersion()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAPIVersion</h4>
<pre>public static&nbsp;java.lang.String&nbsp;getAPIVersion()</pre>
<dl><dt><span class="strong">Returns:</span></dt><dd>The version ID of this API library.</dd></dl>
</li>
</ul>
<a name="createDataClient(android.app.Activity, com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a>&nbsp;createDataClient(android.app.Activity&nbsp;activity,
                                     <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                     java.lang.String&nbsp;language,
                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                     java.lang.String&nbsp;primaryOrSecondaryKey)</pre>
<div class="block">Create a DataRecognitionClient -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return only text 
 recognition results.  The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createDataClient(android.app.Activity, com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a>&nbsp;createDataClient(android.app.Activity&nbsp;activity,
                                     <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                     java.lang.String&nbsp;language,
                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                     java.lang.String&nbsp;url)</pre>
<div class="block">Create a DataRecognitionClient with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return only text 
 recognition results.  The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createDataClient(com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a>&nbsp;createDataClient(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                     java.lang.String&nbsp;language,
                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                     java.lang.String&nbsp;primaryOrSecondaryKey)</pre>
<div class="block">Create a DataRecognitionClient -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection.
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createDataClient(com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClient.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClient</a>&nbsp;createDataClient(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                     java.lang.String&nbsp;language,
                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                     java.lang.String&nbsp;url)</pre>
<div class="block">Create a DataRecognitionClient with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection.
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createDataClientWithIntent(android.app.Activity, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a>&nbsp;createDataClientWithIntent(android.app.Activity&nbsp;activity,
                                                         java.lang.String&nbsp;language,
                                                         <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                         java.lang.String&nbsp;primaryOrSecondaryKey,
                                                         java.lang.String&nbsp;luisAppId,
                                                         java.lang.String&nbsp;luisSubscriptionId)</pre>
<div class="block">Create a DataRecognitionClientWithIntent -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return both text recognition 
 results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service. 
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createDataClientWithIntent(android.app.Activity, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a>&nbsp;createDataClientWithIntent(android.app.Activity&nbsp;activity,
                                                         java.lang.String&nbsp;language,
                                                         <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                         java.lang.String&nbsp;primaryOrSecondaryKey,
                                                         java.lang.String&nbsp;luisAppId,
                                                         java.lang.String&nbsp;luisSubscriptionId,
                                                         java.lang.String&nbsp;url)</pre>
<div class="block">Create a DataRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return both text recognition 
 results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service. 
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createDataClientWithIntent(java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a>&nbsp;createDataClientWithIntent(java.lang.String&nbsp;language,
                                                         <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                         java.lang.String&nbsp;primaryOrSecondaryKey,
                                                         java.lang.String&nbsp;luisAppId,
                                                         java.lang.String&nbsp;luisSubscriptionId)</pre>
<div class="block">Create a DataRecognitionClientWithIntent -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return both text recognition 
 results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createDataClientWithIntent(java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/DataRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">DataRecognitionClientWithIntent</a>&nbsp;createDataClientWithIntent(java.lang.String&nbsp;language,
                                                         <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                         java.lang.String&nbsp;primaryOrSecondaryKey,
                                                         java.lang.String&nbsp;luisAppId,
                                                         java.lang.String&nbsp;luisSubscriptionId,
                                                         java.lang.String&nbsp;url)</pre>
<div class="block">Create a DataRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition with data (for example from a file or audio source).
 The data is broken up into buffers and each buffer is sent to the Speech Recognition Service.
 No modification is done to the buffers, so the user can apply their own Silence Detection. Return both text recognition 
 results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.
 The audio must be PCM, mono, 16-bit sample, with sample rate of 8000 Hz or 16000 Hz.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created DataRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClient(android.app.Activity, com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a>&nbsp;createMicrophoneClient(android.app.Activity&nbsp;activity,
                                                 <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                                 java.lang.String&nbsp;language,
                                                 <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                 java.lang.String&nbsp;primaryOrSecondaryKey)</pre>
<div class="block">Create a MicrophoneRecognitionClient -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return only text 
 recognition results.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClient(android.app.Activity, com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a>&nbsp;createMicrophoneClient(android.app.Activity&nbsp;activity,
                                                 <a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                                 java.lang.String&nbsp;language,
                                                 <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                 java.lang.String&nbsp;primaryOrSecondaryKey,
                                                 java.lang.String&nbsp;url)</pre>
<div class="block">Create a MicrophoneRecognitionClient with Acoustic Model Adaptation -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return only text 
 recognition results.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClient(com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a>&nbsp;createMicrophoneClient(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                                 java.lang.String&nbsp;language,
                                                 <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                 java.lang.String&nbsp;primaryOrSecondaryKey)</pre>
<div class="block">Create a MicrophoneRecognitionClient -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClient(com.microsoft.ProjectOxford.SpeechRecognitionMode, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClient</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClient.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClient</a>&nbsp;createMicrophoneClient(<a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford">SpeechRecognitionMode</a>&nbsp;speechRecognitionMode,
                                                 java.lang.String&nbsp;language,
                                                 <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                 java.lang.String&nbsp;primaryOrSecondaryKey,
                                                 java.lang.String&nbsp;url)</pre>
<div class="block">Create a MicrophoneRecognitionClient with Acoustic Model Adaptation -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>speechRecognitionMode</code> - In ShortPhrase mode the client gets one final multiple n-best choice result and
                              in LongDictation mode the client will receive multiple final results, based on
                              where the server thinks sentence pauses are.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClient.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClientWithIntent(android.app.Activity, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a>&nbsp;createMicrophoneClientWithIntent(android.app.Activity&nbsp;activity,
                                                                     java.lang.String&nbsp;language,
                                                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                                                     java.lang.String&nbsp;luisAppId,
                                                                     java.lang.String&nbsp;luisSubscriptionId)</pre>
<div class="block">Create a MicrophoneRecognitionClientWithIntent -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClientWithIntent(android.app.Activity, java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a>&nbsp;createMicrophoneClientWithIntent(android.app.Activity&nbsp;activity,
                                                                     java.lang.String&nbsp;language,
                                                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                                                     java.lang.String&nbsp;luisAppId,
                                                                     java.lang.String&nbsp;luisSubscriptionId,
                                                                     java.lang.String&nbsp;url)</pre>
<div class="block">Create a MicrophoneRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>activity</code> - The hosting activity context.</dd><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClientWithIntent(java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createMicrophoneClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a>&nbsp;createMicrophoneClientWithIntent(java.lang.String&nbsp;language,
                                                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                                                     java.lang.String&nbsp;luisAppId,
                                                                     java.lang.String&nbsp;luisSubscriptionId)</pre>
<div class="block">Create a MicrophoneRecognitionClientWithIntent -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time to replace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
<a name="createMicrophoneClientWithIntent(java.lang.String, com.microsoft.ProjectOxford.ISpeechRecognitionServerEvents, java.lang.String, java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>createMicrophoneClientWithIntent</h4>
<pre>public static&nbsp;<a href="../../../com/microsoft/ProjectOxford/MicrophoneRecognitionClientWithIntent.html" title="class in com.microsoft.ProjectOxford">MicrophoneRecognitionClientWithIntent</a>&nbsp;createMicrophoneClientWithIntent(java.lang.String&nbsp;language,
                                                                     <a href="../../../com/microsoft/ProjectOxford/ISpeechRecognitionServerEvents.html" title="interface in com.microsoft.ProjectOxford">ISpeechRecognitionServerEvents</a>&nbsp;eventHandlers,
                                                                     java.lang.String&nbsp;primaryOrSecondaryKey,
                                                                     java.lang.String&nbsp;luisAppId,
                                                                     java.lang.String&nbsp;luisSubscriptionId,
                                                                     java.lang.String&nbsp;url)</pre>
<div class="block">Create a MicrophoneRecognitionClientWithIntent with Acoustic Model Adaptation -- for speech recognition from the microphone.  The microphone is
 turned on and data from the microphone is sent to the Speech Recognition Service.  A built in
 Silence Detector is applied to the microphone data before it is sent to the recognition service. Return both 
 text recognition results as well as structured intent results in JSON form from the LUIS (see https://LUIS.ai) service.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>language</code> - The language of the speech being recognized.  Examples include:
     <br>American English: "en-us"
     <br>British English: "en-gb"
     <br>German: "de-de"
     <br>Spanish: "es-es"
     <br>French: "fr-fr"
     <br>Italian: "it-it"
     <br>Mandarin: "zh-cn"</dd><dd><code>eventHandlers</code> - An implementation of ISpeechRecognitionServerEvents that has all of the handler
                      methods for each kind of event.</dd><dd><code>primaryOrSecondaryKey</code> - The primary or the secondary key.  If you want to change the key (which is probably a good idea to do every once in a while 
                              in case it gets leaked somehow), you would have some downtime if there was only one key available.  
                              So you get two, the primary and the secondary.  If you disable one key the other key will still work
                              giving you time toreplace the disabled one.</dd><dd><code>luisAppId</code> - Once you have configured the LUIS service to create and publish an intent model (see https://LUIS.ai)
                  you will be given an Application ID guid.  Use that GUID here.</dd><dd><code>luisSubscriptionId</code> - Once you create a LUIS account (see https://LUIS.ai) you will be given an Subscription ID.
                           Use that secret here.</dd><dd><code>url</code> - The endpoint with a Acoustic Model that you specially created with the Acoustic Model Specialization Service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the created MicrophoneRecognitionClientWithIntent.</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/microsoft/ProjectOxford/SpeechRecognitionMode.html" title="enum in com.microsoft.ProjectOxford"><span class="strong">Prev Class</span></a></li>
<li>Next Class</li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/microsoft/ProjectOxford/SpeechRecognitionServiceFactory.html" target="_top">Frames</a></li>
<li><a href="SpeechRecognitionServiceFactory.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
